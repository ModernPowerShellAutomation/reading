<!DOCTYPE html>

<html lang="es">
<head>
<meta charset="utf-8"/>
<title>
   Translation Part 19 - Translated (es/) - Part 19
  </title>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="" name="language"/>
<meta content="es" name="sourcelang"/>
<meta content="General" name="topic"/>
<meta content="noindex" name="robots"/>
<link href="../style.css" rel="stylesheet"/>
<style>
   .row { display: flex; border-bottom: 1px solid #eee; padding: 10px 0; }
    .col1, .col2 { flex: 1; padding: 0 10px; }
    .col2 em { color: #555; }
    #header { margin-bottom: 2em; border-bottom: 2px solid #000; padding-bottom: 10px; }
    #header h1 { font-size: 1.8em; margin-bottom: 0.2em; }
    #wordcount, #part { font-style: italic; color: #666; font-size: 0.95em; }
    @media (max-width: 768px) {
      .row { flex-direction: column; }
      .col1, .col2 { padding: 5px 0; }
    }
  </style>
</head>
<body>
<div id="header">
<h1>
    Translation Part 19
   </h1>
<p id="wordcount">
    Word Count (Part): 2010
   </p>
<p id="part">
    Part 19
   </p>
</div>
<div id="sentence-table">
<div class="row">
<div class="col1">
<p>
      Y resulta que hay una interpretación elegante de esa área: si escogemos de manera aleatoria a alguien que sobrevivió realmente y a alguien que no, hay una probabilidad del 82 % de que el algoritmo le asigne al superviviente real una mayor probabilidad de sobrevivir que al no superviviente.
     </p>
</div>
<div class="col2">
<p>
      And it turns out that there is an elegant interpretation of that area: if we utterly choose someone who really survived and someone who does not, there is a probability of 82 % that the algorithm assigns the real survivor a greater probability of surviving than the non -survivor.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Las áreas por encima de 0,8 representan una muy buena capacidad de discriminación.
     </p>
</div>
<div class="col2">
<p>
      The areas above 0.8 represent a very good discrimination capacity.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El área por debajo de la curva ROC sirve para medir lo bien que el algoritmo diferencia a los supervivientes de los no supervivientes, pero no la bondad de las probabilidades.
     </p>
</div>
<div class="col2">
<p>
      The area below the ROC curve serves to measure how well the algorithm differentiates the survivors of non -survivors, but not the goodness of the probabilities.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Las personas que estánmás familiarizadas con las predicciones probabilísticas son los meteorólogos.
     </p>
</div>
<div class="col2">
<p>
      People who are more familiar with probabilistic predictions are meteorologists.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Supongamos que queremos predecir si lloverá o no mañana en un momento dado y en un sitio en particular.
     </p>
</div>
<div class="col2">
<p>
      Suppose we want to predict whether or not tomorrow will rain at a given time and in a particular place.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Unos algoritmos básicos nos darían simplemente una respuesta de sí o no, que podría terminar siendo correcta o errónea.
     </p>
</div>
<div class="col2">
<p>
      Basic algorithms would simply give us a response of itself or not, which could end up being correct or wrong.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Modelos más sofisticados podrían generar una probabilidad de que llueva, lo que permitiría hacer juicios más precisos —qué hacer si el algoritmo dice que hay una probabilidad del 50 % de que llueva podría ser muy diferente de si dice que esa probabilidad es del 5 %—.
     </p>
</div>
<div class="col2">
<p>
      More sophisticated models could generate a probability that it rains, which would allow more precise judgments - which if the algorithm says that there is a 50 % probability that it rains could be very different from whether it says that this probability is 5 % -.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Figura 6.
     </p>
</div>
<div class="col2">
<p>
      Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      4.
     </p>
</div>
<div class="col2">
<p>
      4.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Curvas ROC para el árbol de clasificación de la figura 6.
     </p>
</div>
<div class="col2">
<p>
      ROC curves for the classification tree of Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      3 aplicadas a los conjuntos de entrenamiento (línea discontinua) y de validación (línea sólida).
     </p>
</div>
<div class="col2">
<p>
      3 applied to training sets (discontinuous line) and validation (solid line).
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La «sensibilidad» es la proporción de supervivientes correctamente identificados.
     </p>
</div>
<div class="col2">
<p>
      "Sensitivity" is the proportion of correctly identified survivors.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La «especificidad» es la proporción de no supervivientes correctamente etiquetados como no supervivientes.
     </p>
</div>
<div class="col2">
<p>
      "Specificity" is the proportion of non -survivors correctly labeled as non -survivors.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Las áreas bajo las curvas son de 0,84 y 0,82 para los conjuntos de entrenamiento y validación respectivamente.
     </p>
</div>
<div class="col2">
<p>
      The areas under the curves are 0.84 and 0.82 for training and validation sets respectively.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      ¿Cómo sabemos lo buenas que son las predicciones sobre la «probabilidad de precipitación»?
     </p>
</div>
<div class="col2">
<p>
      How do we know how good the predictions about the "probability of precipitation" are?
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      En la práctica, la meteorología se basa en modelos informáticos extremadamente complejos basados a su vez en detalladas fórmulas matemáticas que representan cómo evoluciona el tiempo a partir de las condiciones actuales, y cada estimación del modelo produce una predicción determinista de lluvia del tipo sí o no para un momento y lugar determinados.
     </p>
</div>
<div class="col2">
<p>
      In practice, meteorology is based on extremely complex computer models based on detailed mathematical formulas that represent how time evolves from the current conditions, and each estimate of the model produces a deterministic prediction of rain of the type yes or not for a specific moment and place.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      De manera que para generar una predicción probabilística, el modelo tiene que ser estimado muchas veces, comenzando por unas condiciones iniciales ligeramente ajustadas, que producen una lista de distintos «futuros posibles», en algunos de los cuales llueve, mientras que en otros no.
     </p>
</div>
<div class="col2">
<p>
      So to generate a probabilistic prediction, the model has to be estimated many times, starting with slightly tight initial conditions, which produce a list of different "possible future", in some of which it rains, while in others it does not.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Los meteorólogos estiman un conjunto de, digamos, cincuenta modelos, y si llueve en un lugar y momento determinados en cinco de esos futuros posibles, afirman que hay una «probabilidad de precipitación» del 10 %.
     </p>
</div>
<div class="col2">
<p>
      Meteorologists estimate a set of, say, fifty models, and if it rains in a certain place and moment in five of those possible futures, they affirm that there is a "probability of precipitation" of 10 %.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Pero ¿cómo comprobamos hasta qué punto esas probabilidades son acertadas?
     </p>
</div>
<div class="col2">
<p>
      But how do we verify to what extent those probabilities are successful?
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      No podemos crear una sencilla matriz de errores como en el árbol de clasificación, dado que el algoritmo en ningún momento declara categóricamente si lloverá o no.
     </p>
</div>
<div class="col2">
<p>
      We cannot create a simple error matrix as in the classification tree, since the algorithm at any time declares categorically whether it will rain or not.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Podemos crear curvas ROC, pero estas solo se referirán a si en los días en los que llueve se obtienen predicciones más altas que en los que no.
     </p>
</div>
<div class="col2">
<p>
      We can create ROC curves, but these will only refer to whether in the days in which it rains, higher predictions are obtained than those that are not.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Lo más importante es que necesitamos además realizar una calibración, en el sentido de que si juntamos todos los días en los que el meteorólogo dice que hay una probabilidad de lluvia del 70 %, debería llover en aproximadamente un 70 % de esos días.
     </p>
</div>
<div class="col2">
<p>
      The most important thing is that we also need to make a calibration, in the sense that if we meet every day in which the meteorologist says that there is a probability of rain of 70 %, it should rain in approximately 70 % of those days.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto es algo que los meteorólogos se toman muy en serio: las probabilidades deben realmente querer decir lo que dicen, y no sobreestimar o subestimar.
     </p>
</div>
<div class="col2">
<p>
      This is something that meteorologists take very seriously: probabilities should really mean what they say, and not overestimate or underestimate.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Los gráficos de calibración nos permiten evaluar la fiabilidad de las probabilidades estimadas, juntando, por ejemplo, los eventos a los que se les asigna una probabilidad determinada de ocurrencia, y calculando la proporción de esos eventos que realmente se produjeron.
     </p>
</div>
<div class="col2">
<p>
      Calibration graphics allow us to evaluate the reliability of the estimated probabilities, gathering, for example, the events assigned a certain probability of occurrence, and calculating the proportion of those events that really occurred.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La figura 6.
     </p>
</div>
<div class="col2">
<p>
      Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      5 muestra el gráfico de calibración para el árbol de clasificación simple aplicado al conjunto de validación.
     </p>
</div>
<div class="col2">
<p>
      5 shows the calibration graph for the simple classification tree applied to the validation set.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Queremos que los puntos estén cerca de la línea diagonal, dado que es ahí donde las probabilidades predichas coinciden con los porcentajes observados.
     </p>
</div>
<div class="col2">
<p>
      We want the points to be close to the diagonal line, since that is where the predicted probabilities coincide with the percentages observed.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Las barras verticales señalan una región en la cual, dadas unas probabilidades predichas fiables, esperaríamos que el porcentaje real se diese en el 95 % de los casos.
     </p>
</div>
<div class="col2">
<p>
      The vertical bars indicate a region in which, given reliable predicities, we would expect the real percentage to be given in 95 % of cases.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Si incluimos una línea diagonal, como en la figura 6.
     </p>
</div>
<div class="col2">
<p>
      If we include a diagonal line, as in Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      5, podemos considerar que nuestro algoritmo está bien calibrado.
     </p>
</div>
<div class="col2">
<p>
      5, we can consider that our algorithm is well calibrated.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Figura 6.
     </p>
</div>
<div class="col2">
<p>
      Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      5.
     </p>
</div>
<div class="col2">
<p>
      5.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Gráfico de calibración para el árbol de clasificación simple que proporciona probabilidades de supervivencia al hundimiento del Titanic, con el porcentaje observado de supervivientes en el eje y, y el porcentaje predicho en el eje x.
     </p>
</div>
<div class="col2">
<p>
      Calibration graph for the simple classification tree that provides probabilities of survival to the sinking of the Titanic, with the observed percentage of survivors on the Y axis, and the predicted percentage in the X axis.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Queremos que los puntos se encuentren en la línea diagonal, lo que significaría que las probabilidades son fiables y quieren decir lo que dicen.
     </p>
</div>
<div class="col2">
<p>
      We want the points to be in the diagonal line, which would mean that the probabilities are reliable and mean what they say.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Una medida combinada de «precisión» para las probabilidades La curva ROC evalúa lo bien que el algoritmo divide los grupos, y el gráfico de calibración evalúa si las probabilidades quieren decir lo que dicen.
     </p>
</div>
<div class="col2">
<p>
      A combined measure of "precision" for probabilities The ROC curve evaluates how well the algorithm divides the groups, and the calibration chart evaluates whether the probabilities mean what they say.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Resultaría mejor encontrar una medida compuesta que combine ambos aspectos en una cifra única que pudiésemos utilizarpara comparar algoritmos.
     </p>
</div>
<div class="col2">
<p>
      It would be better to find a compound measure that combines both aspects in a unique figure that we could use to compare algorithms.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Afortunadamente, los meteorólogos se ocuparon de ello en la década de 1950.
     </p>
</div>
<div class="col2">
<p>
      Fortunately, meteorologists took care of it in the 1950s.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Si estuviésemos prediciendo una cantidad numérica, como la temperatura que hará mañana a mediodía en un sitio en particular, la fiabilidad normalmente estaría resumida en el error —la diferencia entre la temperatura observada y la predicha—.
     </p>
</div>
<div class="col2">
<p>
      If we were predicting a numerical amount, such as the temperature that will do tomorrow at noon in a particular place, reliability would normally be summarized in error - the difference between the temperature observed and the predicted.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El resumen normal de los errores a lo largo de varios días es el error cuadrático medio (ECM) —la media del cuadrado de los errores, algo parecido al criterio de mínimos cuadrados que se usa en el análisis de regresión—.
     </p>
</div>
<div class="col2">
<p>
      The normal summary of errors over several days is the average quadratic error (ECM) - the average of the square of errors, something similar to the criteria of square minimums used in the regression analysis.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El truco para calcular probabilidades es usar el mismo error cuadrático medio que cuando predecimos una cantidad, pero asignando un valor 1 a la observación futura de «lluvia» y de 0 a la de «no lluvia».
     </p>
</div>
<div class="col2">
<p>
      The trick to calculate probabilities is to use the same average quadratic error as when we predict an amount, but assigning a value 1 to the future observation of "rain" and from 0 to that of "no rain."
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La tabla 6.
     </p>
</div>
<div class="col2">
<p>
      Table 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      2 muestra cómo funcionaría este criterio en el caso de un sistema meteorológico ficticio.
     </p>
</div>
<div class="col2">
<p>
      2 shows how this criterion would work in the case of a fictional meteorological system.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El lunes se asigna una probabilidad de 0,1 a que llueva, pero resulta que no llueve (la respuesta verdadera es 0), por lo que el error es 0 − 0,1 = −0,1.
     </p>
</div>
<div class="col2">
<p>
      On Monday a probability of 0.1 is assigned to it rains, but it turns out that it does not rain (the true answer is 0), so the error is 0 - 0.1 = −0.1.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto se eleva al cuadrado para obtener 0,01, y así sucesivamente a lo largo de la semana.
     </p>
</div>
<div class="col2">
<p>
      This rises squared to obtain 0.01, and so on throughout the week.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La media de estos errores al cuadrado, B = 0,11, es una medida de la precisión (o de falta de ella) del meteorólogo.
     </p>
</div>
<div class="col2">
<p>
      The average of these errors square, b = 0.11, is a measure of the precision (or lack of it) of the meteorologist.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      [94] El error cuadrático medio se conoce como puntuación de Brier, por el meteorólogo Glenn Brier, que describió el método en 1950.
     </p>
</div>
<div class="col2">
<p>
      [94] The average quadratic error is known as Brier's score, by meteorologist Glenn Brier, who described the method in 1950.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Por desgracia, la puntuación de Brier no es fácil de interpretar en sus propios términos, y, por ello, es difícil saber si un meteorólogo lo está haciendo bien o mal; es mejor comparar su predicción con una puntuación de referencia derivada del historial climatológico.
     </p>
</div>
<div class="col2">
<p>
      Unfortunately, Brier's score is not easy to interpret in his own terms, and, therefore, it is difficult to know if a meteorologist is doing it right or wrong; It is better to compare its prediction with a reference score derived from the weather history.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Estas predicciones «basadas en el clima» no tienen en cuenta las condiciones actuales y establecen simplemente la probabilidad de precipitación como el porcentaje de veces en la historia climatológica en las que llovió ese día.
     </p>
</div>
<div class="col2">
<p>
      These "weather -based" predictions do not take into account the current conditions and simply establish the probability of precipitation as the percentage of times in the weather history in which it rained that day.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Cualquiera puede hacer una predicción de ese tipo sin necesidad de tener ningún conocimiento; en la tabla 6.
     </p>
</div>
<div class="col2">
<p>
      Anyone can make such a prediction without having any knowledge; In Table 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      2 asumimos que esto significa asignar una probabilidad del 20 % delluvia para cada día de la semana.
     </p>
</div>
<div class="col2">
<p>
      2 We assume that this means assigning a 20 % probability of the Luvia for each day of the week.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto da una puntuación de Brier para la climatología (lo que llamamos BC) de 0,28.
     </p>
</div>
<div class="col2">
<p>
      This gives a Brier score for weather (what we call BC) of 0.28.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Tabla 6.
     </p>
</div>
<div class="col2">
<p>
      Table 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      2.
     </p>
</div>
<div class="col2">
<p>
      2.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Predicción ficticia de la «probabilidad de precipitación» de si lloverá o no a mediodía del día siguiente en una localidad específica, con resultado observado: 1 = llovió, 0 = no llovió.
     </p>
</div>
<div class="col2">
<p>
      Fictional prediction of the "probability of precipitation" of whether or not it will rain at noon the next day in a specific locality, with observed result: 1 = rained, 0 = did not rain.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El «error» es la diferencia entre el resultado predicho y observado, y el error cuadrático medio es la puntuación de Brier (B).
     </p>
</div>
<div class="col2">
<p>
      The "error" is the difference between the predicted and observed result, and the middle quadratic error is the Brier (B) score.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La puntuación climatológica de Brier (BC) se basa en el uso de los porcentajes medios a largo plazo de lluvia en esa época del año como predicciones probabilísticas, que en este caso se asume que son de un 20 % todos los días.
     </p>
</div>
<div class="col2">
<p>
      Brier's weather score (BC) is based on the use of long -term average percentages of rain at that time of year as probabilistic predictions, which in this case is assumed that they are 20 % every day.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Cualquier algoritmo predictivo decente debería funcionar mejor que las predicciones basadas exclusivamente en el historial climatológico, y, en ese sentido, nuestro sistema predictivo mejora la puntuación en BC − B = 0,28 − 0,11 = 0,17.
     </p>
</div>
<div class="col2">
<p>
      Any decent predictive algorithm should work better than predictions based exclusively on climatological history, and, in that sense, our predictive system improves the score in BC - b = 0.28 - 0.11 = 0.17.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Los meteorólogos crearon a continuación un «índice de habilidad», que mide la reducción proporcional de la puntuación de referencia: en nuestro caso es 0,61,[95] lo que significa que nuestro algoritmo mejora enun 61 % a un meteorólogo aficionado que use solo datos climatológicos.
     </p>
</div>
<div class="col2">
<p>
      Meteorologists then created a "skill index", which measures the proportional reduction of the reference score: in our case it is 0.61, [95] which means that our algorithm improves in a 61 % improvement to an amateur meteorologist who uses only climatological data.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Claramente nuestro objetivo es el 100 %, pero solo alcanzaríamos esa cifra si nuestra puntuación de Brier observada se redujese a 0, lo que solo ocurre si predecimos exactamente si lloverá o no.
     </p>
</div>
<div class="col2">
<p>
      Clearly our goal is 100 %, but we would only reach that figure if our observed Brier score be reduced to 0, which only happens if we predict exactly if it will rain or not.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto sería mucho esperar de cualquier meteorólogo, y, de hecho, el índice de habilidad para la predicción de lluvia está ahora en torno al 0,4 para el día siguiente, y al 0,2 para las predicciones a una semana.
     </p>
</div>
<div class="col2">
<p>
      This would be much to expect from any meteorologist, and, in fact, the skill index for rain prediction is now around 0.4 for the next day, and 0.2 for a week predictions.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      [96] Por supuesto, la predicción menos trabajada de todas diría simplemente que lo que pase hoy también ocurrirá mañana, lo que proporciona un ajuste perfecto a los datos históricos (hoy), pero podría no ser particularmente buena para predecir el futuro.
     </p>
</div>
<div class="col2">
<p>
      [96] Of course, the least worked prediction of all would simply say that what happens today will also happen tomorrow, which provides a perfect adjustment to historical data (today), but it may not be particularly good to predict the future.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Volviendo al desafío del Titanic, considérese el algoritmo sencillo consistente en asignar a todo el mundo una probabilidad del 39 % de supervivencia, que es el porcentaje global de supervivientes en el conjunto de entrenamiento.
     </p>
</div>
<div class="col2">
<p>
      Returning to the Titanic challenge, consider the simple algorithm consisting of assigning to the whole world a 39 % survival probability, which is the global percentage of survivors in the training set.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      No estaríamos usando datos individuales, y, en esencia, sería el equivalente a predecir el tiempo con el historial climatológico en lugar de información sobre las circunstancias actuales.
     </p>
</div>
<div class="col2">
<p>
      We would not be using individual data, and, in essence, it would be the equivalent of predicting time with the weather history instead of information about current circumstances.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La puntuación de Brier para este índice de «ausencia de habilidades» es de 0,232.
     </p>
</div>
<div class="col2">
<p>
      Brier's score for this "absence of skills" index is 0.232.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Por el contrario, la puntuación de Brier para el árbol de clasificación simple es de 0,139, lo que supone una reducción de un 40 % con respecto a esa predicción de aficionado, y, en ese sentido, demuestra una habilidad considerable.
     </p>
</div>
<div class="col2">
<p>
      On the contrary, Brier's score for the simple classification tree is 0.139, which represents a 40 % reduction with respect to that fan prediction, and, in that sense, demonstrates a considerable ability.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Otra forma de interpretar esta puntuación de Brier de 0,139 es que es exactamente lo que habríamos obtenido si otorgásemos a todos los supervivientes una probabilidad del 63 % de sobrevivir, y a todos los no supervivientes una probabilidad del 63 % de no sobrevivir.
     </p>
</div>
<div class="col2">
<p>
      Another way to interpret this 0.139 Brier score is that it is exactly what we would have obtained if we granted all survivors a 63 % probability of surviving, and to all non -survivors a 63 % probability of not surviving.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Veremos si podemos mejorar esa puntuación con algunos modelos más complicados, pero primero tenemos que advertir de que quizá es mejor que no sean demasiado complicados.
     </p>
</div>
<div class="col2">
<p>
      We will see if we can improve that score with some more complicated models, but first we have to warn that it may not be too complicated.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Sobreajuste No necesitamos quedarnos en el sencillo árbol de clasificación mostrado en la figura 6.
     </p>
</div>
<div class="col2">
<p>
      Overjack we do not need to stay in the simple classification tree shown in Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      3.
     </p>
</div>
<div class="col2">
<p>
      3.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Podemos hacer el árbol más y más complejo añadiendo nuevas ramas, lo que nos permitiría clasificar correctamente una parte mayor del conjunto de entrenamiento, a medida que identificamos un creciente número de sus características.
     </p>
</div>
<div class="col2">
<p>
      We can make the tree more and more complex by adding new branches, which would allow us to correctly classify a greater part of the training set, as we identify a growing number of its characteristics.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Figura 6.
     </p>
</div>
<div class="col2">
<p>
      Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      6.
     </p>
</div>
<div class="col2">
<p>
      6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Árbol de clasificación sobreajustado para los datos del Titanic.
     </p>
</div>
<div class="col2">
<p>
      OVERJUSED CLASSIFICATION TREE FOR TITANIC DATA.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Como en la figura 6.
     </p>
</div>
<div class="col2">
<p>
      As in Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      3, el porcentaje al final de cada rama es la proporción de pasajeros en el conjunto de entrenamiento que sobrevivió, y se predice que un nuevo pasajero sobrevivirá si ese porcentaje es mayor del 50 %.
     </p>
</div>
<div class="col2">
<p>
      3, the percentage at the end of each branch is the proportion of passengers in the training set that survived, and it is predicted that a new passenger will survive if that percentage is greater than 50 %.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El conjunto más bien extraño de preguntas sugiere que el árbol se ha adaptado demasiado a los casos individuales del conjunto de entrenamiento.
     </p>
</div>
<div class="col2">
<p>
      The rather strange set of questions suggests that the tree has adapted too much to individual cases of the training set.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La figura 6.
     </p>
</div>
<div class="col2">
<p>
      Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      6 muestra un árbol de ese tipo, ampliado para poder incluir muchos detalles.
     </p>
</div>
<div class="col2">
<p>
      6 shows such a tree, extended to include many details.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Tiene una precisión de 83 % con respecto alconjunto de entrenamiento, mejor que el árbol más pequeño.
     </p>
</div>
<div class="col2">
<p>
      It has an 83 % accuracy with respect to training, better than the smallest tree.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Pero cuando aplicamos este algoritmo a los datos del conjunto de validación, su precisión se reduce al 81 %, la misma que la del árbol pequeño, y su puntuación de Brier es 0,150, claramente peor que el árbol sencillo, cuya puntuación es 0,139.
     </p>
</div>
<div class="col2">
<p>
      But when we apply this algorithm to the validation set data, its precision is reduced to 81 %, the same as that of the small tree, and its Brier score is 0.150, clearly worse than the simple tree, whose score is 0.139.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Hemos adaptado el árbol a los datos de entrenamiento hasta tal punto que su capacidad predictiva ha comenzado a descender.
     </p>
</div>
<div class="col2">
<p>
      We have adapted the tree to training data to such an extent that its predictive capacity has begun to descend.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto se conoce como sobreajuste, y es una de las cuestiones más importantes en la construcción de algoritmos.
     </p>
</div>
<div class="col2">
<p>
      This is known as overjuste, and is one of the most important issues in the construction of algorithms.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Al hacer el algoritmo demasiado complejo, esencialmente estamos ajustando el ruido, en lugar de la señal.
     </p>
</div>
<div class="col2">
<p>
      When making the algorithm too complex, we are essentially adjusting the noise, instead of the signal.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Randall Munroe (el dibujante conocido por su tira cómica xkcd) ilustró brillantemente lo que supone el sobreajuste.
     </p>
</div>
<div class="col2">
<p>
      Randall Munroe (the cartoonist known for his comic strip XKCD) brilliantly illustrated what the overhap.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Enunció una serie de «reglas» plausibles seguidas en las elecciones presidenciales de Estados Unidos, solo para ser rotas en elecciones subsiguientes.
     </p>
</div>
<div class="col2">
<p>
      He enunciated a series of plausible "rules" in a row in the presidential elections of the United States, only to be broken in subsequent elections.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      [97] Por ejemplo: «Ningún republicano ha ganado sin controlar la Cámara o el Senado» (hasta que lo hizo Eisenhower en 1952).
     </p>
</div>
<div class="col2">
<p>
      [97] For example: "No Republican has won without controlling the camera or the Senate" (until Eisenhower did in 1952).
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      «Los católicos no pueden ganar» (hasta Kennedy en 1960).
     </p>
</div>
<div class="col2">
<p>
      "Catholics cannot win" (until Kennedy in 1960).
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      «Nadie ha sido elegido presidente después de un divorcio» (hasta Reagan en 1980).
     </p>
</div>
<div class="col2">
<p>
      "No one has been elected president after a divorce" (until Reagan in 1980).
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Y así sucesivamente, incluidas algunas reglas claramente sobrerrefinadas, como la siguiente: «Ningún presidente demócrata sin experiencia en combate ha derrotado a alguien cuyo nombre tenga más puntos en el Scrabble» (hasta que Bill [6 puntos en el Scrabble] Clinton derrotó a Bob [7 puntos en el Scrabble] Dole en 1996).
     </p>
</div>
<div class="col2">
<p>
      And so on, including some rules clearly overref, such as the following: "No Democratic president without experience in combat has defeated someone whose name has more points in the Scrabble" (until Bill [6 points in the Scrabble] Clinton defeated Bob [7 points in the Scrabble] Dole in 1996).
     </p>
</div>
</div>
</div>
</body>
</html>
