<!DOCTYPE html>

<html lang="es">
<head>
<meta charset="utf-8"/>
<title>
   Translation Part 20 - Translated (es/) - Part 20
  </title>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="" name="language"/>
<meta content="es" name="sourcelang"/>
<meta content="General" name="topic"/>
<meta content="noindex" name="robots"/>
<link href="../style.css" rel="stylesheet"/>
<style>
   .row { display: flex; border-bottom: 1px solid #eee; padding: 10px 0; }
    .col1, .col2 { flex: 1; padding: 0 10px; }
    .col2 em { color: #555; }
    #header { margin-bottom: 2em; border-bottom: 2px solid #000; padding-bottom: 10px; }
    #header h1 { font-size: 1.8em; margin-bottom: 0.2em; }
    #wordcount, #part { font-style: italic; color: #666; font-size: 0.95em; }
    @media (max-width: 768px) {
      .row { flex-direction: column; }
      .col1, .col2 { padding: 5px 0; }
    }
  </style>
</head>
<body>
<div id="header">
<h1>
    Translation Part 20
   </h1>
<p id="wordcount">
    Word Count (Part): 2017
   </p>
<p id="part">
    Part 20
   </p>
</div>
<div id="sentence-table">
<div class="row">
<div class="col1">
<p>
      Sobreajustamos cuando nos adaptamos demasiado a las circunstancias locales, en un esfuerzo meritorio pero equivocado por evitar ser «sesgados» y para tener en cuenta toda la información disponible.
     </p>
</div>
<div class="col2">
<p>
      We overhap when we adapt too much to local circumstances, in a meritorious effort but wrong to avoid being "biased" and to take all the information available.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Normalmente aplaudiríamos ese deseo de evitar sesgos, pero es un refinamiento que significa que tenemos menos datos conlos que trabajar, de manera que la fiabilidad se reduce.
     </p>
</div>
<div class="col2">
<p>
      Normally we would applaud that desire to avoid biases, but it is a refinement that means that we have less data with them than to work, so that reliability is reduced.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El sobreajuste, por tanto, lleva a menos sesgo, pero a costa de una mayor incertidumbre o variación en los estimadores, y es por ello por lo que la protección contra el sobreajuste a menudo se conoce como solución de compromiso sesgo-varianza.
     </p>
</div>
<div class="col2">
<p>
      The overjuste, therefore, leads to less bias, but at the expense of greater uncertainty or variation in the estimators, and that is why the protection against the overjuste is often known as a bias-variance compromise solution.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Podemos ilustrar esta sutil idea imaginando una base de datos enorme sobre la vida de la gente que se use para predecir la salud que tendrá usted en el futuro; por ejemplo, su probabilidad de llegar a los 80 años.
     </p>
</div>
<div class="col2">
<p>
      We can illustrate this subtle idea imagining a huge database about the life of the people used to predict the health you will have in the future; For example, its probability of reaching 80 years.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Podríamos, quizás, observar a todas las personas de su grupo de edad y estatus socioeconómico, y ver qué les pasa; podría haber 10.
     </p>
</div>
<div class="col2">
<p>
      We could, perhaps, observe all the people in their age group and socioeconomic status, and see what happens to them; There could be 10.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      000 personas con esas características.
     </p>
</div>
<div class="col2">
<p>
      000 people with those characteristics.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Si 8.
     </p>
</div>
<div class="col2">
<p>
      Yes 8.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      000 de ellas alcanzan los 80 años, podríamos estimar que existe una probabilidad del 80 % de que la gente como usted alcance los 80 años, y estar bastante seguros acerca de esa cifra, dado que se basa en un gran número de personas.
     </p>
</div>
<div class="col2">
<p>
      000 of them reach 80 years, we could estimate that there is a probability of 80 % that people like you reach 80 years, and be quite safe about that figure, since it is based on a large number of people.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Pero esta estimación solo usa un par de características para emparejarle con los casos en la base de datos, e ignora características más individuales que podrían refinar nuestra predicción: por ejemplo, no hay información sobre su salud actual o sus hábitos.
     </p>
</div>
<div class="col2">
<p>
      But this estimate only uses a couple of characteristics to match you with cases in the database, and ignore more individual characteristics that could refine our prediction: for example, there is no information about your current health or your habits.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Una estrategia diferente consistiría en encontrar personas que se pareciesen más a usted, con el mismo peso, estatura, presión sanguínea, colesterol, hábitos de ejercicio, consumo de tabaco y alcohol, y así sucesivamente: digamos que le emparejamos con personas con más y más características, hasta reducir la comparación a solo dos personas en la base de datos que serían casi iguales.
     </p>
</div>
<div class="col2">
<p>
      A different strategy would consist of finding people who look more like you, with the same weight, height, blood pressure, cholesterol, exercise habits, tobacco and alcohol consumption, and so on: let's say that we match people with people with more and more characteristics, until reducing the comparison to only two people in the database that would be almost equal.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Supongamos que una de ellas ha alcanzado los 80 años y la otra no.
     </p>
</div>
<div class="col2">
<p>
      Suppose one of them has reached 80 years and the other does not.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      ¿Estimaríamos entonces una probabilidad del 50 % de que usted llegase a cumplir 80?
     </p>
</div>
<div class="col2">
<p>
      Would we then estimate a 50 % probability that you were 80?
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esa cifra del 50 % es, en este sentido, menos sesgada, dado que la otra persona se parece mucho a usted, pero, dado que solo se basa en dos personas, no es un estimador fiable (a saber, tiene una gran varianza).
     </p>
</div>
<div class="col2">
<p>
      That 50 % figure is, in this sense, less biased, since the other person looks a lot like you, but, since it is only based on two people, it is not a reliable estimator (namely, it has a great variance).
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Intuitivamente sentimos que hay un punto medio entre estos dos extremos; encontrar ese equilibrio es complicado pero crucial.
     </p>
</div>
<div class="col2">
<p>
      I intuitively feel that there is a midpoint between these two extremes; Finding that balance is complicated but crucial.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Una técnica para evitar el sobreajuste es la regularización, que suponeestimar modelos complejos, pero donde los efectos de las variables son reducidos a cero.
     </p>
</div>
<div class="col2">
<p>
      A technique to avoid landing is regularization, which involves stating complex models, but where the effects of the variables are reduced to zero.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Pero quizá la protección más común es usar la idea sencilla pero potente de la validación cruzada cuando se construye el algoritmo.
     </p>
</div>
<div class="col2">
<p>
      But perhaps the most common protection is to use the simple but powerful idea of cross validation when the algorithm is built.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Es esencial comprobar cualquier predicción sobre un conjunto de validación independiente que no se haya usado en el entrenamiento del algoritmo, pero eso solo pasa al final del proceso de desarrollo.
     </p>
</div>
<div class="col2">
<p>
      It is essential to check any prediction on an independent validation set that has not been used in the training of the algorithm, but that only happens to the end of the development process.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      De manera que, aunque podría mostrar nuestro sobreajuste en ese momento, no nos proporciona un mejor algoritmo.
     </p>
</div>
<div class="col2">
<p>
      So, although it could show our village at that time, it does not provide us with a better algorithm.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Podemos, no obstante, imitar una validación independiente eliminando, digamos, un 10 % de los datos de entrenamiento, desarrollar el algoritmo sobre el restante 90 %, y la validación sobre ese 10 % eliminado.
     </p>
</div>
<div class="col2">
<p>
      We can, however, imitate an independent validation eliminating, say, 10 % of the training data, develop the algorithm on the remaining 90 %, and the validation of that 10 % eliminated.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto es la validación cruzada, y puede llevarse a cabo sistemáticamente eliminando el 10 % y repitiendo el procedimiento diez veces, lo que se conoce como validación cruzada decuplicada.
     </p>
</div>
<div class="col2">
<p>
      This is cross validation, and can be carried out systematically eliminating 10 % and repeating the procedure ten times, which is known as cross validation.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Todos los algoritmos mencionados en este capítulo tienen algunos parámetros regulables cuya función principal es controlar la complejidad del algoritmo final.
     </p>
</div>
<div class="col2">
<p>
      All the algorithms mentioned in this chapter have some adjustable parameters whose main function is to control the complexity of the final algorithm.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Por ejemplo, el procedimiento estándar para construir árboles de clasificación es, primero, construir un árbol muy profundo, con muchas ramas, que esté deliberadamente sobreajustado, y después podar el árbol para hacerlo más simple y más robusto: esta poda está controlada por un parámetro de complejidad.
     </p>
</div>
<div class="col2">
<p>
      For example, the standard procedure to build classification trees is, first, to build a very deep tree, with many branches, which is deliberately superjusted, and then prune the tree to make it simpler and more robust: this pruning is controlled by a complexity parameter.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Este parámetro de complejidad puede ser escogido a través del proceso de validación cruzada.
     </p>
</div>
<div class="col2">
<p>
      This complexity parameter can be chosen through the cross validation process.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Para cada una de las diez muestras de validación cruzada, se desarrolla un árbol para cada uno de los distintos parámetros de complejidad.
     </p>
</div>
<div class="col2">
<p>
      For each of the ten cross validation samples, a tree is developed for each of the different complexity parameters.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Para cada valor del parámetro, se calcula el desempeño predicho medio a lo largo de los diez conjuntos de validación cruzada (este desempeño medio tenderá a mejorar hasta cierto punto, y después empeorará a medida que los árboles se hacen demasiado complejos).
     </p>
</div>
<div class="col2">
<p>
      For each parameter value, the medium predicted performance is calculated throughout the ten cross validation sets (this average performance will tend to improve to some extent, and then worsen as trees become too complex).
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El valor óptimo del parámetro de complejidad es el que proporciona el mejor desempeño de validación cruzada, y este valor se usa a continuaciónpara construir un árbol a partir del conjunto de entrenamiento completo, que es la versión final.
     </p>
</div>
<div class="col2">
<p>
      The optimal value of the complexity parameter is the one that provides the best cross validation performance, and this value is used below to build a tree from the complete training set, which is the final version.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Hemos empleado la validación cruzada decuplicada para seleccionar el parámetro de complejidad en el árbol de la figura 6.
     </p>
</div>
<div class="col2">
<p>
      We have used the decipated cross validation to select the complexity parameter in the tree from Figure 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      3, y para escoger parámetros ajustados en todos los modelos que consideraremos a continuación.
     </p>
</div>
<div class="col2">
<p>
      3, and to choose adjusted parameters in all the models that we will consider below.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Modelos de regresión Vimos en el capítulo 5 que la idea del modelo de regresión es utilizar una fórmula sencilla para predecir un resultado.
     </p>
</div>
<div class="col2">
<p>
      Regression models we saw in chapter 5 that the idea of the regression model is to use a simple formula to predict a result.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La variable de respuesta en los datos del Titanic es del tipo sí o no, referida a si se ha sobrevivido o no, y, por ello, lo apropiado es una regresión logística, como en el caso de los datos de cirugía cardiaca infantil de la figura 5.
     </p>
</div>
<div class="col2">
<p>
      The response variable in the titanic data is of the yes or not type, referred to whether or not it has survived, and, therefore, the appropriate is a logistics regression, as in the case of the data of child cardiac surgery of Figure 5.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      2.
     </p>
</div>
<div class="col2">
<p>
      2.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La tabla 6.
     </p>
</div>
<div class="col2">
<p>
      Table 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      3 muestra los resultados de una regresión logística.
     </p>
</div>
<div class="col2">
<p>
      3 shows the results of a logistics regression.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Se ha utilizado el boosting, un procedimiento interactivo diseñado para prestar una mayor atención a los casos más difíciles: a aquellos individuos en el conjunto de entrenamiento que están clasificados incorrectamente en una iteración se les confiere más peso en la siguiente iteración.
     </p>
</div>
<div class="col2">
<p>
      Boosting has been used, an interactive procedure designed to pay greater attention to the most difficult cases: those individuals in the training set that are incorrectly classified into an iteration is conferred more weight in the following iteration.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El número de iteraciones se decide mediante la validación cruzada decuplicada.
     </p>
</div>
<div class="col2">
<p>
      The number of iterations is decided by decipated cross validation.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Los coeficientes para las características de un pasajero concreto pueden ser sumados para obtener un índice total de supervivencia.
     </p>
</div>
<div class="col2">
<p>
      The coefficients for the characteristics of a specific passenger can be added to obtain a total survival index.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Por ejemplo, Francis Somerton empezaría con 3,20, se le restaría 2,30 por ir en tercera clase y 3,86 por recibir el título de «Mr», pero se le sumaría 1,43 por ser un hombre que viaja en tercera clase.
     </p>
</div>
<div class="col2">
<p>
      For example, Francis Somerton would start with 3.20, 2.30 would be subtracted in third class and 3.86 for receiving the title of "MR", but 1.43 would be added for being a man traveling in the third class.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Pierde 0,38 por estar en una familia de un único miembro, lo que nos da una puntuación total de −1,91, lo que, a su vez, se traduce en una probabilidad de supervivencia del 13 %, ligeramente inferior al 16 % que nos daría el árbol de clasificación simple.
     </p>
</div>
<div class="col2">
<p>
      It loses 0.38 for being in a family of a single member, which gives us a total score of −1.91, which, in turn, translates into a probability of survival of 13 %, slightly less than 16 % that would give us the simple classification tree.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      [98] Se trata de un sistema «lineal», pero nótese que se han incluido interacciones, que son esencialmente características combinadas más complejas, por ejemplo, la puntuación positiva para lainteracción de viajar en tercera clase y ser hombre ayuda a contrarrestar las puntuaciones extremadamente negativas de viajar en tercera clase y recibir el título de «Mr», que ya hemos tenido en cuenta.
     </p>
</div>
<div class="col2">
<p>
      [98] It is a "linear" system, but notice that interactions have been included, which are essentially more complex combined characteristics, for example, the positive score for the interaction of third -class traveling and being a man helps to counteract extremely negative scores of traveling in third class and receiving the title of "MR", which we have already taken into account.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Aunque nos estamos centrando en desempeño predictivo, estos coeficientes sí que proporcionan alguna interpretación de la importancia de las diferentes características.
     </p>
</div>
<div class="col2">
<p>
      Although we are focusing on predictive performance, these coefficients do provide some interpretation of the importance of different characteristics.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Tabla 6.
     </p>
</div>
<div class="col2">
<p>
      Table 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      3.
     </p>
</div>
<div class="col2">
<p>
      3.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Coeficientes aplicados a características en una regresión logística con datos de supervivientes del Titanic: los coeficientes negativos disminuyen la probabilidad de supervivencia, los coeficientes positivos incrementan esa probabilidad.
     </p>
</div>
<div class="col2">
<p>
      Coefficients applied to characteristics in a logistic regression with data from Titanic Survivors: negative coefficients decrease the probability of survival, positive coefficients increase that probability.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Existen análisis de regresión más sofisticados para tratar problemas grandes y complejos, como por ejemplo los modelos no lineales y un proceso conocido como LASSO, que estima simultáneamente coeficientes y selecciona variables independientes relevantes, esencialmente estimando que sus coeficientes sean cero.
     </p>
</div>
<div class="col2">
<p>
      There are more sophisticated regression analysis to treat big and complex problems, such as non -linear models and a process known as Lasso, which simultaneously estimates coefficients and selects relevant independent variables, essentially estimating that their coefficients are zero.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Técnicas más complejas Los árboles de clasificación y los modelos de regresión surgen de filosofías algo distintas sobre cómo modelizar: los árboles intentan construir reglas simples que identifiquen grupos de casos con resultados esperados similares, mientras que los modelos de regresión se centran en el peso que hay que asignar a característicasespecíficas, con independencia de cualquier otra cosa que observemos en un caso.
     </p>
</div>
<div class="col2">
<p>
      More complex techniques classification trees and regression models arise from somewhat different philosophies on how to model: trees try to build simple rules that identify groups of cases with similar expected results, while regression models focus on the weight that must be assigned to specific characteristics, regardless of anything else we observe in one case.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La comunidad dedicada al aprendizaje automático usa árboles de clasificación y regresiones, pero ha desarrollado una amplia gama de métodos alternativos y más complejos para desarrollar algoritmos.
     </p>
</div>
<div class="col2">
<p>
      The community dedicated to automatic learning uses classification and regressions, but has developed a wide range of alternative and more complex methods to develop algorithms.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Por ejemplo: Bosques aleatorios, que comprenden un gran número de árboles, cada uno de los cuales produce una clasificación.
     </p>
</div>
<div class="col2">
<p>
      For example: random forests, which comprise a large number of trees, each of which produces a classification.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La clasificación final se decide por voto mayoritario, un proceso conocido como empaquetado.
     </p>
</div>
<div class="col2">
<p>
      The final classification is decided by majority vote, a process known as packaging.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Máquinas de vectores de soporte, que intentan encontrar una combinación lineal de aquellas características que separen mejor los distintos resultados.
     </p>
</div>
<div class="col2">
<p>
      Support vector machines, which try to find a linear combination of those characteristics that better separate the different results.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Redes neuronales, que comprenden estratos de nodos, cada uno de los cuales depende del anterior de manera ponderada, como si se tratase de una serie de regresiones logísticas unas encima de otras.
     </p>
</div>
<div class="col2">
<p>
      Neural networks, which include nodes strata, each of which depends on the previous one in a weighted way, as if it were a series of logistic regressions on top of each other.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Los pesos de cada estrato se determinan por medio de un procedimiento de optimización, y, como en el caso de los bosques aleatorios, se pueden construir múltiples redes neuronales y extraer una media.
     </p>
</div>
<div class="col2">
<p>
      The weights of each stratum are determined by means of an optimization procedure, and, as in the case of random forests, multiple neural networks can be built and an average of extract.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Las redes neuronales con muchos estratos se conocen como modelos de aprendizaje profundo: se dice que el sistema de reconocimiento de imágenes de Google, Inception, tiene alrededor de veinte estratos y unos trescientos mil parámetros que estimar.
     </p>
</div>
<div class="col2">
<p>
      Neuronal networks with many strata are known as deep learning models: it is said that Google's image recognition system, Inception, has about twenty strata and about three hundred thousand parameters to estimate.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      K vecinos más cercanos clasifica de acuerdo con el resultado mayoritario entre casos parecidos del conjunto de entrenamiento.
     </p>
</div>
<div class="col2">
<p>
      K closest neighbors classify according to the majority result between similar cases of the training set.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Los resultados de aplicar algunos de estos métodos a los datos del Titanic, con parámetros ajustados escogidos a través de la validación cruzada decuplicada y ROC como criterio de optimización, se muestran en la tabla 6.
     </p>
</div>
<div class="col2">
<p>
      The results of applying some of these methods to the Titanic data, with chosen tight parameters through the decupplicated cross validation and ROC as optimization criteria, are shown in Table 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      4.
     </p>
</div>
<div class="col2">
<p>
      4.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      La alta precisión de la sumamente elemental regla según la cual «todas las mujeres sobreviven, todos los hombres no sobreviven», que o bien queda por delante o solo un poco por detrás de algoritmos más complejos, demuestra lo inadecuado de una «precisión» cruda como medida de desempeño.
     </p>
</div>
<div class="col2">
<p>
      The high precision of the extremely elementary rule according to which "all women survive, all men do not survive", which either remains ahead or just a little behind more complex algorithms, demonstrates the inappropriate of a raw "precision" as a performance measure.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El bosque aleatorio produce la mejor discriminación, lo que se refleja en el área por debajo de la curva ROC, aunque, quizás sorprendentemente, las probabilidades provenientes del sencillo árbol de clasificación tienen la mejor puntuación de Brier.
     </p>
</div>
<div class="col2">
<p>
      The random forest produces the best discrimination, which is reflected in the area below the ROC curve, although, perhaps surprisingly, the probabilities from the simple classification tree have the best Brier score.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      No hay, en definitiva, ningún algoritmo claramente ganador.
     </p>
</div>
<div class="col2">
<p>
      There is, in short, any clearly winning algorithm.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Más adelante, en el capítulo 10, comprobaremos si realmente podemos afirmar con seguridad que hay un ganador en cual quiera de estos criterios, dado que los márgenes de victoria podrían ser tan pequeños como para poder ser explicados como el resultado de una variación aleatoria —como, por ejemplo, quién termina el primero en los conjuntos de validación y entrenamiento—.
     </p>
</div>
<div class="col2">
<p>
      Later, in Chapter 10, we will check if we can really say that there is a winner in which he wants these criteria, given that Victoria's margins could be so small as to be explained as the result of a random variation - as, for example, who ends the first in the validation and training sets.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Tabla 6.
     </p>
</div>
<div class="col2">
<p>
      Table 6.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      4.
     </p>
</div>
<div class="col2">
<p>
      4.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Coeficientes aplicados a características en una regresión logística con datos de supervivientes del Titanic: los coeficientes negativos disminuyen la probabilidad de supervivencia, los coeficientes positivos incrementan esa probabilidad.
     </p>
</div>
<div class="col2">
<p>
      Coefficients applied to characteristics in a logistic regression with data from Titanic Survivors: negative coefficients decrease the probability of survival, positive coefficients increase that probability.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto refleja una inquietud general sobre los algoritmos ganadores de competiciones de Kaggle; a saber, que tienden a ser muy complejos, y todo para obtener ese margen minúsculo que se necesita para ganar.
     </p>
</div>
<div class="col2">
<p>
      This reflects a general restlessness on Kaggy's winning competition algorithms; Namely, they tend to be very complex, and everything to obtain that tiny margin that is needed to win.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Un problema importante es que estos algoritmos tienden a ser cajas negras inescrutables: generan una predicción, pero es casi imposible determinar qué ocurre en su interior.
     </p>
</div>
<div class="col2">
<p>
      An important problem is that these algorithms tend to be inscrutable black boxes: they generate a prediction, but it is almost impossible to determine what happens inside.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto tiene tres consecuencias negativas.
     </p>
</div>
<div class="col2">
<p>
      This has three negative consequences.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      En primer lugar, su complejidad extrema hace que su puesta en práctica y su mejora supongan un esfuerzo descomunal: cuando Netflix ofreció un premio de un millón de dólares al mejor sistema predictivo derecomendaciones, el algoritmo ganador era tan complicado que Netflix terminó por no usarlo.
     </p>
</div>
<div class="col2">
<p>
      First, its extreme complexity makes its implementation and its improvement suppose a huge effort: when Netflix offered a prize of one million dollars to the best predictive system, the winning algorithm was so complicated that Netflix ended up not using it.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Otra característica negativa es que no sabemos cómo se ha alcanzado el resultado, o cuánta confianza podemos tener en este: nuestra única opción es aceptarlo o rechazarlo.
     </p>
</div>
<div class="col2">
<p>
      Another negative characteristic is that we do not know how the result has been achieved, or how much confidence we can have in this: our only option is to accept or reject it.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Los algoritmos más sencillos se explican mejor.
     </p>
</div>
<div class="col2">
<p>
      The simplest algorithms are best explained.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Finalmente, si no sabemos cómo produce sus respuestas un algoritmo, no podemos investigar si tiene un sesgo implícito pero sistemático contra algunos miembros de la comunidad —algo que desarrollaré más en detalle más adelante—.
     </p>
</div>
<div class="col2">
<p>
      Finally, if we do not know how an algorithm produces its answers, we cannot investigate whether it has an implicit but systematic bias against some members of the community - something I will develop more in detail later.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Todo ello apunta a que quizá el desempeño cuantitativo no sea el mejor criterio para un algoritmo.
     </p>
</div>
<div class="col2">
<p>
      All this indicates that perhaps quantitative performance is not the best criterion for an algorithm.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Una vez que el desempeño es «lo suficientemente bueno», podría ser razonable preferir que el algoritmo sea sencillo, aun a costa de pequeñas mejoras.
     </p>
</div>
<div class="col2">
<p>
      Once the performance is "good enough," it could be reasonable to prefer that the algorithm is simple, even at the expense of small improvements.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      ¿Quién fue la persona más afortunada del Titanic?
     </p>
</div>
<div class="col2">
<p>
      Who was the luckiest person in Titanic?
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      El superviviente con la puntuación de Brier más alta cuando se hace la media de todos los algoritmos podría ser considerado también como el caso más sorprendente de todos.
     </p>
</div>
<div class="col2">
<p>
      The survivor with the highest Brier score when the average of all algorithms is made could also be considered as the most surprising case of all.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Se trata de Karl Dahl, un carpintero noruego-australiano de 45 años que viajaba en tercera clase, y que había pagado la misma tarifa que Francis Somerton; dos algoritmos le confirieron una probabilidad de supervivencia del 0 %.
     </p>
</div>
<div class="col2">
<p>
      This is Karl Dahl, a 45-year-old Norwegian-Australian carpenter who was traveling in the third class, and who had paid the same rate as Francis Somerton; Two algorithms conferred a probability of survival of 0 %.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Aparentemente se arrojó al agua helada y se subió al bote salvavidas 15, a pesar de que algunos de los pasajeros intentaron impedirlo.
     </p>
</div>
<div class="col2">
<p>
      Apparently he threw himself into the icy water and climbed into the life boat 15, despite the fact that some of the passengers tried to prevent it.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Quizá simplemente usó su fuerza.
     </p>
</div>
<div class="col2">
<p>
      Maybe he simply used his strength.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      Esto contrasta con el caso de Francis Somerton, de Ilfracombe, cuya muerte, como hemos visto, encajaba con la pauta general.
     </p>
</div>
<div class="col2">
<p>
      This contrasts with the case of Francis Somerton, of Ilfracombe, whose death, as we have seen, fit the general pattern.
     </p>
</div>
</div>
<div class="row">
<div class="col1">
<p>
      En lugar de tener un marido exitoso en América, a su mujer, Hannah Somerton, solo le quedaron cinco libras esterlinas, menos de lo que Francis gastó en su billete.
     </p>
</div>
<div class="col2">
<p>
      Instead of having a successful husband in America, his wife, Hannah Somerton, only had five pounds, less than Francis spent on his ticket.
     </p>
</div>
</div>
</div>
</body>
</html>
